seed: 42
sft_model_path: ../models/r_clm_v2/last
train_path: ../datasets/dpo/dpo_train.parquet
test_path: ../datasets/dpo/dpo_test.parquet

dpo:
  beta: 0.05
  logging_first_step: true
  max_prompt_length: 64
  max_length: 840
  optim: rmsprop
  remove_unused_columns: false


lora:
  target_modules:
    - q_proj
    - k_proj
    - v_proj
    - out_proj
  r: 16
  lora_alpha: 16
  lora_dropout: 0.1
  modules_to_save:
    - lm_head

output_dir: ../models/r_dpo_v2

learning_rate: 1.0e-5
# lr_scheduler_type: linear
per_device_train_batch_size: 1
per_device_eval_batch_size: 1
gradient_accumulation_steps: 8
num_train_epochs: 1
warmup_ratio: 0.05
max_grad_norm: 1.0